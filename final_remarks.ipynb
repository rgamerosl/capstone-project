{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import required libraries\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics \n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make sure that 'ggplot' style is used for all plots\n",
    "plt.style.use('ggplot')\n",
    "# plt.style.available ### To view all other available styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set Working Directory (WD)\n",
    "os.chdir('/Volumes/GoogleDrive/My Drive/CEMEX/Data Translators/GitHub/rgamerosl/capstone-project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read Final Datasets using pickle\n",
    "# df = pickle.load(open('dataset/data_v2.pkl', 'rb'))\n",
    "new_data = pickle.load(open('dataset/data_12f_vf.pkl', 'rb'))\n",
    "data = pickle.load(open('dataset/data_42f_vf.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read Tree base Models\n",
    "new_best_rf = pickle.load(open('dataset/PythonModels/RandomForest_19F.pkl', 'rb'))\n",
    "best_rf = pickle.load(open('dataset/PythonModels/RandomForest_36F.pkl', 'rb'))\n",
    "new_rfecv_RF = pickle.load(open('dataset/PythonModels/RandomForestRFE_19F.pkl', 'rb'))\n",
    "rfecv_RF = pickle.load(open('dataset/PythonModels/RandomForestRFE_36F.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read LinearRegression Models\n",
    "new_est2 = pickle.load(open('dataset/PythonModels/LinearRegression_19F.pkl', 'rb'))\n",
    "est2 = pickle.load(open('dataset/PythonModels/LinearRegression_36F.pkl', 'rb'))\n",
    "new_rfecv_LR = pickle.load(open('dataset/PythonModels/LinearRegressionRFE_19F.pkl', 'rb'))\n",
    "rfecv_LR = pickle.load(open('dataset/PythonModels/LinearRegressionRFE_36F.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pairplot that takes a LOT of time\n",
    "\n",
    "# sns.pairplot(new_data, palette='husl', corner=True, diag_kind='kde', kind='reg', markers='.', \n",
    "#                  plot_kws={'line_kws':{'color':'red', 'alpha':0.5}}, height=1.5)\n",
    "# plt.savefig(f'figures/paitplots.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data['Speed'], density=True, bins=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['liters_per_hour']\n",
    "x = data['Speed']\n",
    "\n",
    "plt.scatter(x, y, alpha=0.3, color='b')\n",
    "\n",
    "z = np.polyfit(x, y, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(x,p(x),\"r--\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best10cols = new_data.columns[0:10].values.tolist()\n",
    "best10cols.append('liters_per_hour')\n",
    "best10cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select the best 10 features and rerun both models: RandomForest and LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select variables, Train/Test Split and Standarised numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_data = new_data[best10cols]\n",
    "mini_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_data_train, mini_data_test = train_test_split(mini_data, test_size=0.25, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col = mini_data.columns[[0,1,2,4,7,8,9,10]]\n",
    "print(num_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standarize numerical variables in Train Set\n",
    "scaler = StandardScaler()\n",
    "mini_data_train_scale = mini_data_train.copy(deep=True)\n",
    "mini_data_train_scale[num_col] = scaler.fit_transform(mini_data_train[num_col].to_numpy()) \n",
    "display(mini_data_train_scale.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standarize numerical variables in Test Set\n",
    "scaler = StandardScaler()\n",
    "mini_data_test_scale = mini_data_test.copy(deep=True)\n",
    "mini_data_test_scale[num_col] = scaler.fit_transform(mini_data_test[num_col].to_numpy()) \n",
    "display(mini_data_test_scale.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_X_train = mini_data_train_scale.loc[:, mini_data_train_scale.columns != 'liters_per_hour'].values\n",
    "mini_y_train = mini_data_train_scale['liters_per_hour'].values\n",
    "\n",
    "mini_X_test = mini_data_test_scale.loc[:, mini_data_test_scale.columns != 'liters_per_hour'].values\n",
    "mini_y_test = mini_data_test_scale['liters_per_hour'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adjusting Best model to answer the following questions\n",
    "\n",
    "mini_best_rf = RandomForestRegressor(n_estimators=80, n_jobs=-1, random_state=1, max_features='sqrt',\n",
    "                                min_samples_leaf=2, min_samples_split=2, max_depth=None, bootstrap=False)\n",
    "mini_best_rf.fit(mini_X_train, mini_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_best_rf_y_train_pred = mini_best_rf.predict(mini_X_train)\n",
    "mini_best_rf_train_MSE_score = mean_squared_error(mini_y_train, mini_best_rf_y_train_pred)\n",
    "print(\"MSE for the Best Random Forest in the Train data:\", round(mini_best_rf_train_MSE_score,4))\n",
    "mini_best_rf_train_R2_score = r2_score(mini_y_train, mini_best_rf_y_train_pred)\n",
    "print(\"R2 for the Best Random Forest in the Train data:\", round(mini_best_rf_train_R2_score,4))\n",
    "\n",
    "mini_best_rf_y_test_pred = mini_best_rf.predict(mini_X_test)\n",
    "mini_best_rf_test_MSE_score = mean_squared_error(mini_y_test, mini_best_rf_y_test_pred)\n",
    "print(\"MSE for the Best Random Forest in the Test data:\", round(mini_best_rf_test_MSE_score,4))\n",
    "mini_best_rf_test_R2_score = r2_score(mini_y_test, mini_best_rf_y_test_pred)\n",
    "print(\"R2 for the Best Random Forest in the Test data:\", round(mini_best_rf_test_R2_score,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = mini_best_rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in mini_best_rf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.barh(range(mini_X_train.shape[1]), importances[indices],\n",
    "       color=\"r\", xerr=std[indices], align=\"center\")\n",
    "# If you want to define your own labels,\n",
    "# change indices to a list of labels on the following line.\n",
    "plt.yticks(range(mini_X_train.shape[1]), mini_data_train_scale.loc[:, mini_data_train_scale.columns != 'liters_per_hour'].columns[indices[::1]])\n",
    "plt.ylim([-1, mini_X_train.shape[1]])\n",
    "plt.savefig(f'figures/mini_feature_importances.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use RFECV with the complete data (X_train contains 36 different variables)\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "min_features_to_select = 1  # Minimum number of features to consider\n",
    "mini_rfecv_RF = RFECV(estimator=mini_best_rf, step=1, cv=5,\n",
    "              scoring='r2',\n",
    "              min_features_to_select=min_features_to_select)\n",
    "\n",
    "mini_rfecv_RF.fit(mini_X_train, mini_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal number of features : %d\" % mini_rfecv_RF.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation R2 score\")\n",
    "plt.plot(range(min_features_to_select,\n",
    "               len(mini_rfecv_RF.grid_scores_) + min_features_to_select),\n",
    "         mini_rfecv_RF.grid_scores_)\n",
    "plt.title(\"RFE - Random Forest\")\n",
    "plt.savefig(f'figures/mini_RFE_RF.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(mini_best_rf, mini_X_train, mini_y_train, cv=5, scoring='r2')\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearRegression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_X2_train = sm.add_constant(mini_X_train)\n",
    "est = sm.OLS(mini_y_train, mini_X2_train)\n",
    "mini_est = est.fit()\n",
    "print(mini_est.summary())\n",
    "\n",
    "### Doubt: How to interpret coefficients with non-standarized data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_y_train_pred_lr = mini_est.predict(mini_X2_train)\n",
    "mini_lr_train_MSE_score = mean_squared_error(mini_y_train, mini_y_train_pred_lr)\n",
    "print(\"MSE for the Multiple Linear Regression in the Train data:\", round(mini_lr_train_MSE_score,4))\n",
    "mini_lr_train_R2_score = r2_score(mini_y_train, mini_y_train_pred_lr)\n",
    "print(\"R2 for the Multiple Linear Regression in the Train data:\", round(mini_lr_train_R2_score,4))\n",
    "\n",
    "mini_X2_test = sm.add_constant(mini_X_test)\n",
    "mini_y_test_pred_lr = mini_est.predict(mini_X2_test)\n",
    "mini_lr_test_MSE_score = mean_squared_error(mini_y_test, mini_y_test_pred_lr)\n",
    "print(\"MSE for the Multiple Linear Regression in the Test data:\", round(mini_lr_test_MSE_score,4))\n",
    "mini_lr_test_R2_score = r2_score(mini_y_test, mini_y_test_pred_lr)\n",
    "print(\"R2 for the Multiple Linear Regression in the Test data:\", round(mini_lr_test_R2_score,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "def calc_vif(X):\n",
    "\n",
    "    # Calculating VIF\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"Features\"] = X.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "    return(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### First VIF Analysis with all numerical variables (data)\n",
    "mini_vif_y = mini_data['liters_per_hour']\n",
    "mini_vif_X = mini_data.drop('liters_per_hour',axis=1)\n",
    "mini_vif_model = calc_vif(mini_vif_X)\n",
    "mini_vif_model.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use RFECV with the complete data (X_train contains 36 different variables)\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "min_features_to_select = 1  # Minimum number of features to consider\n",
    "mini_rfecv_LR = RFECV(estimator=lr, step=1, cv=5,\n",
    "              scoring='r2',\n",
    "              min_features_to_select=min_features_to_select)\n",
    "\n",
    "mini_rfecv_LR.fit(mini_X2_train, mini_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal number of features : %d\" % mini_rfecv_LR.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation R2 score\")\n",
    "plt.plot(range(min_features_to_select,\n",
    "               len(mini_rfecv_LR.grid_scores_) + min_features_to_select),\n",
    "         mini_rfecv_LR.grid_scores_)\n",
    "plt.title(\"RFE - Linear Regression\")\n",
    "plt.savefig(f'figures/mini_RFE_LR.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(lr, mini_X2_train, mini_y_train, cv=5, scoring='r2')\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In both cases taking into account the next 10 features only improves the R2 score by ~5%... it seems likes is not worth it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mini_data.columns[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = mini_data['liters_per_hour']\n",
    "for i in mini_data.columns[0:10]:\n",
    "    x = mini_data[str(i)]\n",
    "\n",
    "    plt.scatter(x, y, alpha=0.3, color='b')\n",
    "\n",
    "    z = np.polyfit(x, y, 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(x,p(x),\"r--\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple LinearRegressionusing only Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_X_train.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_X2_train = sm.add_constant(mini_X_train)\n",
    "est = sm.OLS(mini_y_train, mini_X2_train)\n",
    "mini_est = est.fit()\n",
    "print(mini_est.summary())\n",
    "\n",
    "### Doubt: How to interpret coefficients with non-standarized data?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}