{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import required libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import seaborn as sns\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make sure that 'ggplot' style is used for all plots\n",
    "plt.style.use('ggplot')\n",
    "# plt.style.available ### To view all other available styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set Working Directory (WD)\n",
    "os.chdir('/Volumes/GoogleDrive/My Drive/CEMEX/Data Translators/GitHub/rgamerosl/capstone-project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### How to import RDS (equivalent to RData) into pandas\n",
    "\n",
    "# import rpy2.robjects as robjects\n",
    "# from rpy2.robjects.packages import importr\n",
    "# from rpy2.robjects import pandas2ri\n",
    "\n",
    "# from rpy2.robjects.conversion import localconverter\n",
    "\n",
    "# readRDS = robjects.r['readRDS']\n",
    "# rdata = readRDS('dataset/Fuel_Data.RDS')\n",
    "\n",
    "# with localconverter(robjects.default_converter + pandas2ri.converter):\n",
    "#   pdata = robjects.conversion.rpy2py(rdata)\n",
    "\n",
    "# print(pdata.info())\n",
    "# display(pdata.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read the data\n",
    "df = pd.read_csv(\"dataset/Fuel_Data.csv\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fill with 0 the NA for the different events\n",
    "df.iloc[:,16:33] = df.iloc[:,16:33].fillna(0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df.drop(['Date','Plate','Zone','Hrs_eff','Engine_hrs','Fuel_used','km_per_liter'], axis=1)\n",
    "display(df0.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots(figsize=(10,10))\n",
    "ax = sns.heatmap(df0.iloc[:,0:11].corr(), annot=True, fmt='0.2f', cmap='Blues')\n",
    "plt.yticks(rotation=0)\n",
    "# plt.savefig(f'figures/correlations1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = [7,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]\n",
    "fig = plt.subplots(figsize=(16,16))\n",
    "ax = sns.heatmap(df0.iloc[:,subset].corr(), annot=True, fmt='0.2f', cmap='Blues',xticklabels=subset,yticklabels=subset)\n",
    "plt.yticks(rotation=0)\n",
    "# plt.savefig(f'figures/correlations2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df0.dropna(subset=['liters_per_hour'])\n",
    "df1.reset_index(inplace=True)\n",
    "df1.drop('index',axis=1,inplace=True)\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.to_excel('dataset/data_v2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oe_manufacturer = OneHotEncoder()\n",
    "oe_results_m = oe_manufacturer.fit_transform(df1[['Manufacturer']])\n",
    "manufacturer_ohe = pd.DataFrame(oe_results_m.toarray(), columns=oe_manufacturer.categories_)\n",
    "print(display(manufacturer_ohe.head(10)))\n",
    "manufacturer_ohe.columns=np.array(oe_manufacturer.categories_).flatten()\n",
    "manufacturer_ohe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.join(manufacturer_ohe)\n",
    "### Drop column for Kenworth, before droping it the 29 column corresponded to the manufacturer Kenworth\n",
    "df2.drop(df2.columns[29],axis=1,inplace=True)\n",
    "print(display(df2.head(10)))\n",
    "df2.info()"
   ]
  },
  {
   "source": [
    "### Weekdays (0: Monday to 6: Sunday)\n",
    "oe_weekday = OneHotEncoder()\n",
    "oe_results_w = oe_weekday.fit_transform(df2[['Weekday']])\n",
    "weekday_ohe = pd.DataFrame(oe_results_w.toarray(), columns=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'])\n",
    "print(display(weekday_ohe.head(10)))\n",
    "weekday_ohe.columns=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\n",
    "weekday_ohe.info()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.join(weekday_ohe)\n",
    "### Drop column for Friday, before droping it the 34 column corresponded to the label Friday\n",
    "df2.drop(df2.columns[34],axis=1,inplace=True)\n",
    "print(display(df2.head(10)))\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oe_city = OneHotEncoder()\n",
    "oe_results_c = oe_city.fit_transform(df2[['City']])\n",
    "city_ohe = pd.DataFrame(oe_results_c.toarray(), columns=oe_city.categories_)\n",
    "print(display(city_ohe.head(10)))\n",
    "city_ohe.columns=np.array(oe_city.categories_).flatten()\n",
    "city_ohe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.join(city_ohe)\n",
    "### Drop column for MEXICO DF, before droping it the 80 column corresponded to the label MEXICO DF\n",
    "df2.drop(df2.columns[80],axis=1,inplace=True)\n",
    "print(display(df2.head(10)))\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Another approach to categorical/indicator variables using get_dummiyes properly\n",
    "# import pandas as pd\n",
    "\n",
    "# from pandas.api.types import CategoricalDtype \n",
    "\n",
    "# # say you want a column for \"japan\" too (it'll be always zero, of course)\n",
    "# df[\"country\"] = train_df[\"country\"].astype(CategoricalDtype([\"australia\",\"germany\",\"korea\",\"russia\",\"japan\"]))\n",
    "\n",
    "# # now call .get_dummies() as usual\n",
    "# pd.get_dummies(df[\"country\"],prefix='country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.to_excel(\"dataset/final_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df2.drop(['Manufacturer','City','Weekday'],axis=1)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=['Mileage'],axis=0)\n",
    "data.reset_index(inplace=True)\n",
    "data.drop('index',axis=1,inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now need to do Train Test split and afterwards StandardScale all the numerical variables in each set seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Test split\n",
    "data_train, data_test = train_test_split(data, test_size=0.25, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_indexes = data.columns[0:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standarize numerical variables in Train Set\n",
    "scaler = StandardScaler()\n",
    "data_train_scale = data_train.copy(deep=True)\n",
    "data_train_scale[col_indexes] = scaler.fit_transform(data_train[col_indexes].to_numpy()) \n",
    "display(data_train_scale.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standarize numerical variables in Test Set\n",
    "scaler = StandardScaler()\n",
    "data_test_scale = data_test.copy(deep=True)\n",
    "data_test_scale[col_indexes] = scaler.fit_transform(data_test[col_indexes].to_numpy()) \n",
    "display(data_test_scale.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train_scale.loc[:, data_train_scale.columns != 'liters_per_hour'].values\n",
    "y_train = data_train_scale['liters_per_hour'].values\n",
    "\n",
    "X_test = data_test_scale.loc[:, data_test_scale.columns != 'liters_per_hour'].values\n",
    "y_test = data_test_scale['liters_per_hour'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cval_model(X_train,y_train, model='RandomForest', cv=True, LR=0.1):\n",
    "    '''\n",
    "    runs crossvalidation in the specified model and returns the MSE and R2 metrics according to the train dataset\n",
    "    '''\n",
    "    scores = np.zeros(2)\n",
    "    if model == 'RandomForest':\n",
    "        model = RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=1)\n",
    "    elif model == 'GradientBoostin':\n",
    "        model = GradientBoostingRegressor(learning_rate=LR, n_estimators=100, random_state=1)\n",
    "    else:\n",
    "        model = AdaBoostRegressor(DecisionTreeClassifier(), learning_rate=LR, n_estimators=100, random_state=1)\n",
    "    model.fit(X_train, y_train)\n",
    "    if cv:\n",
    "        scores[0] = -1*cross_val_score(model, X_train, y_train, scoring= 'neg_mean_squared_error', cv=5).mean()\n",
    "        scores[1] = cross_val_score(model, X_train, y_train, scoring= 'r2', cv=5).mean()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_rf = cval_model(X_train,y_train,model='RandomForest',cv=True)\n",
    "scores_gdbr = cval_model(X_train,y_train,model='GradientBoostin',cv=True)\n",
    "\n",
    "print(f'RandomForestClassifier       Train CV    |   MSE: {round(scores_rf[0],3)}   |   R2: {round(scores_rf[1],3)}')\n",
    "print(f'GradientBoostinClassifier    Train CV    |   MSE: {round(scores_gdbr[0],3)}  |   R2: {round(scores_gdbr[1],3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Packages require to adjust Multiple Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train = sm.add_constant(X_train)\n",
    "est = sm.OLS(y_train, X2_train)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())\n",
    "\n",
    "### I did not expect all features to be relevant according to the p-value (except for 2 or 4 features only: 29, 30, 33, 35) and some cities\n",
    "### Doubt: How to interpret coefficients with non-standarized data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_lr = est2.predict(X2_train)\n",
    "lr_train_MSE_score = mean_squared_error(y_train, y_train_pred_lr)\n",
    "print(\"MSE for the Multiple Linear Regression in the Train data:\", round(lr_train_MSE_score,4))\n",
    "lr_train_R2_score = r2_score(y_train, y_train_pred_lr)\n",
    "print(\"R2 for the Multiple Linear Regression in the Train data:\", round(lr_train_R2_score,4))\n",
    "\n",
    "X2_test = sm.add_constant(X_test)\n",
    "y_test_pred_lr = est2.predict(X2_test)\n",
    "lr_test_MSE_score = mean_squared_error(y_test, y_test_pred_lr)\n",
    "print(\"MSE for the Multiple Linear Regression in the Test data:\", round(lr_test_MSE_score,4))\n",
    "lr_test_R2_score = r2_score(y_test, y_test_pred_lr)\n",
    "print(\"R2 for the Multiple Linear Regression in the Test data:\", round(lr_test_R2_score,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}