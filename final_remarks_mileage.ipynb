{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import required libraries\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics \n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make sure that 'ggplot' style is used for all plots\n",
    "plt.style.use('ggplot')\n",
    "# plt.style.available ### To view all other available styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set Working Directory (WD)\n",
    "os.chdir('/Volumes/GoogleDrive/My Drive/CEMEX/Data Translators/GitHub/rgamerosl/capstone-project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read Final Datasets using pickle\n",
    "# df = pickle.load(open('dataset/data_v2.pkl', 'rb'))\n",
    "new_data = pickle.load(open('dataset/data_12f_mileage_vf.pkl', 'rb'))\n",
    "data = pickle.load(open('dataset/data_42f_mileage_vf.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read Tree base Models\n",
    "new_best_rf = pickle.load(open('dataset/PythonModels/RandomForest_19F.pkl', 'rb'))\n",
    "best_rf = pickle.load(open('dataset/PythonModels/RandomForest_36F.pkl', 'rb'))\n",
    "new_rfecv_RF = pickle.load(open('dataset/PythonModels/RandomForestRFE_19F.pkl', 'rb'))\n",
    "rfecv_RF = pickle.load(open('dataset/PythonModels/RandomForestRFE_36F.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read LinearRegression Models\n",
    "new_est2 = pickle.load(open('dataset/PythonModels/LinearRegression_19F.pkl', 'rb'))\n",
    "est2 = pickle.load(open('dataset/PythonModels/LinearRegression_36F.pkl', 'rb'))\n",
    "new_rfecv_LR = pickle.load(open('dataset/PythonModels/LinearRegressionRFE_19F.pkl', 'rb'))\n",
    "rfecv_LR = pickle.load(open('dataset/PythonModels/LinearRegressionRFE_36F.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pairplot that takes a LOT of time\n",
    "\n",
    "# sns.pairplot(new_data, palette='husl', corner=True, diag_kind='kde', kind='reg', markers='.', \n",
    "#                  plot_kws={'line_kws':{'color':'red', 'alpha':0.5}}, height=1.5)\n",
    "# plt.savefig(f'figures/paitplots.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data['Mileage'], density=True, bins=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['liters_per_hour']\n",
    "x = data['Mileage']\n",
    "\n",
    "plt.scatter(x, y, alpha=0.3, color='b')\n",
    "\n",
    "z = np.polyfit(x, y, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(x,p(x),\"r--\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best10cols = new_data.columns[0:10].values.tolist()\n",
    "best10cols.append('liters_per_hour')\n",
    "best10cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select the best 10 features and rerun both models: RandomForest and LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select variables, Train/Test Split and Standarised numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_data = new_data[best10cols]\n",
    "mini_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_data_train, mini_data_test = train_test_split(mini_data, test_size=0.25, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col = mini_data.columns[[0,1,2,4,7,8,9,10]]\n",
    "print(num_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standarize numerical variables in Train Set\n",
    "scaler = StandardScaler()\n",
    "mini_data_train_scale = mini_data_train.copy(deep=True)\n",
    "mini_data_train_scale[num_col] = scaler.fit_transform(mini_data_train[num_col].to_numpy()) \n",
    "display(mini_data_train_scale.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standarize numerical variables in Test Set\n",
    "scaler = StandardScaler()\n",
    "mini_data_test_scale = mini_data_test.copy(deep=True)\n",
    "mini_data_test_scale[num_col] = scaler.fit_transform(mini_data_test[num_col].to_numpy()) \n",
    "display(mini_data_test_scale.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_X_train = mini_data_train_scale.loc[:, mini_data_train_scale.columns != 'liters_per_hour'].values\n",
    "mini_y_train = mini_data_train_scale['liters_per_hour'].values\n",
    "\n",
    "mini_X_test = mini_data_test_scale.loc[:, mini_data_test_scale.columns != 'liters_per_hour'].values\n",
    "mini_y_test = mini_data_test_scale['liters_per_hour'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adjusting Best model to answer the following questions\n",
    "\n",
    "mini_best_rf = RandomForestRegressor(n_estimators=80, n_jobs=-1, random_state=1, max_features='sqrt',\n",
    "                                min_samples_leaf=2, min_samples_split=2, max_depth=None, bootstrap=False)\n",
    "mini_best_rf.fit(mini_X_train, mini_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_best_rf_y_train_pred = mini_best_rf.predict(mini_X_train)\n",
    "mini_best_rf_train_MSE_score = mean_squared_error(mini_y_train, mini_best_rf_y_train_pred)\n",
    "print(\"MSE for the Best Random Forest in the Train data:\", round(mini_best_rf_train_MSE_score,4))\n",
    "mini_best_rf_train_R2_score = r2_score(mini_y_train, mini_best_rf_y_train_pred)\n",
    "print(\"R2 for the Best Random Forest in the Train data:\", round(mini_best_rf_train_R2_score,4))\n",
    "\n",
    "mini_best_rf_y_test_pred = mini_best_rf.predict(mini_X_test)\n",
    "mini_best_rf_test_MSE_score = mean_squared_error(mini_y_test, mini_best_rf_y_test_pred)\n",
    "print(\"MSE for the Best Random Forest in the Test data:\", round(mini_best_rf_test_MSE_score,4))\n",
    "mini_best_rf_test_R2_score = r2_score(mini_y_test, mini_best_rf_y_test_pred)\n",
    "print(\"R2 for the Best Random Forest in the Test data:\", round(mini_best_rf_test_R2_score,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = mini_best_rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in mini_best_rf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.barh(range(mini_X_train.shape[1]), importances[indices],\n",
    "       color=\"r\", xerr=std[indices], align=\"center\")\n",
    "# If you want to define your own labels,\n",
    "# change indices to a list of labels on the following line.\n",
    "plt.yticks(range(mini_X_train.shape[1]), mini_data_train_scale.loc[:, mini_data_train_scale.columns != 'liters_per_hour'].columns[indices[::1]])\n",
    "plt.ylim([-1, mini_X_train.shape[1]])\n",
    "plt.savefig(f'figures/mini_feature_importances_mileage.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use RFECV with the complete data (X_train contains 36 different variables)\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "min_features_to_select = 1  # Minimum number of features to consider\n",
    "mini_rfecv_RF = RFECV(estimator=mini_best_rf, step=1, cv=5,\n",
    "              scoring='r2',\n",
    "              min_features_to_select=min_features_to_select)\n",
    "\n",
    "mini_rfecv_RF.fit(mini_X_train, mini_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal number of features : %d\" % mini_rfecv_RF.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation R2 score\")\n",
    "plt.plot(range(min_features_to_select,\n",
    "               len(mini_rfecv_RF.grid_scores_) + min_features_to_select),\n",
    "         mini_rfecv_RF.grid_scores_)\n",
    "plt.title(\"RFE - Random Forest\")\n",
    "plt.savefig(f'figures/mini_RFE_RF_mileageCEM - Pedal del acelerador arriba del 50% con vehículo detenido .png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(mini_best_rf, mini_X_train, mini_y_train, cv=5, scoring='r2')\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearRegression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_X2_train = sm.add_constant(mini_X_train)\n",
    "est = sm.OLS(mini_y_train, mini_X2_train)\n",
    "mini_est = est.fit()\n",
    "print(mini_est.summary())\n",
    "\n",
    "### Doubt: How to interpret coefficients with non-standarized data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_y_train_pred_lr = mini_est.predict(mini_X2_train)\n",
    "mini_lr_train_MSE_score = mean_squared_error(mini_y_train, mini_y_train_pred_lr)\n",
    "print(\"MSE for the Multiple Linear Regression in the Train data:\", round(mini_lr_train_MSE_score,4))\n",
    "mini_lr_train_R2_score = r2_score(mini_y_train, mini_y_train_pred_lr)\n",
    "print(\"R2 for the Multiple Linear Regression in the Train data:\", round(mini_lr_train_R2_score,4))\n",
    "\n",
    "mini_X2_test = sm.add_constant(mini_X_test)\n",
    "mini_y_test_pred_lr = mini_est.predict(mini_X2_test)\n",
    "mini_lr_test_MSE_score = mean_squared_error(mini_y_test, mini_y_test_pred_lr)\n",
    "print(\"MSE for the Multiple Linear Regression in the Test data:\", round(mini_lr_test_MSE_score,4))\n",
    "mini_lr_test_R2_score = r2_score(mini_y_test, mini_y_test_pred_lr)\n",
    "print(\"R2 for the Multiple Linear Regression in the Test data:\", round(mini_lr_test_R2_score,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "def calc_vif(X):\n",
    "\n",
    "    # Calculating VIF\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"Features\"] = X.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "    return(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### First VIF Analysis with all numerical variables (data)\n",
    "mini_vif_y = mini_data['liters_per_hour']\n",
    "mini_vif_X = mini_data.drop('liters_per_hour',axis=1)\n",
    "mini_vif_model = calc_vif(mini_vif_X)\n",
    "mini_vif_model.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use RFECV with the complete data (X_train contains 36 different variables)\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "min_features_to_select = 1  # Minimum number of features to consider\n",
    "mini_rfecv_LR = RFECV(estimator=lr, step=1, cv=5,\n",
    "              scoring='r2',\n",
    "              min_features_to_select=min_features_to_select)\n",
    "\n",
    "mini_rfecv_LR.fit(mini_X2_train, mini_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal number of features : %d\" % mini_rfecv_LR.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation R2 score\")\n",
    "plt.plot(range(min_features_to_select,\n",
    "               len(mini_rfecv_LR.grid_scores_) + min_features_to_select),\n",
    "         mini_rfecv_LR.grid_scores_)\n",
    "plt.title(\"RFE - Linear Regression\")\n",
    "plt.savefig(f'figures/mini_RFE_LR_mileage.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(lr, mini_X2_train, mini_y_train, cv=5, scoring='r2')\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In both cases taking into account the next 10 features only improves the R2 score by ~5%... it seems likes is not worth it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mini_data.columns[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling = mini_data.sample(n=80000, random_state=42)\n",
    "plt.style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pairplot that takes a LOT of time\n",
    "\n",
    "sns.pairplot(sampling, palette='husl', corner=True, diag_kind='kde', kind='reg', markers='.', \n",
    "                 plot_kws={'line_kws':{'color':'red', 'alpha':0.5}}, height=1.5)\n",
    "plt.savefig(f'figures/pairplots_mileage.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sampling['liters_per_hour']\n",
    "for i in sampling.columns[0:10]:\n",
    "    x = sampling[i]\n",
    "\n",
    "    plt.scatter(x, y, alpha=0.3, color='b')\n",
    "    plt.title(f'{i}')\n",
    "    z = np.polyfit(x, y, 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(x,p(x),\"r--\")\n",
    "    plt.savefig(f'figures/{i}-feature_mileage.png', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple LinearRegression using only Mileage and Idle_Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MileF = mini_X2_train[:,0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = sm.OLS(mini_y_train, MileF)\n",
    "mini_est_S = est.fit()\n",
    "print(mini_est_S.summary())\n",
    "\n",
    "### Doubt: How to interpret coefficients with non-standarized data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = sm.OLS(mini_y_train, mini_X2_train[:,0:2])\n",
    "mini_est_S1 = est.fit()\n",
    "print(mini_est_S1.summary())\n",
    "\n",
    "### Doubt: How to interpret coefficients with non-standarized data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_y_train_pred_lrS = mini_est_S.predict(MileF)\n",
    "mini_lrS_train_MSE_score = mean_squared_error(mini_y_train, mini_y_train_pred_lrS)\n",
    "print(\"MSE for the Simple Linear Regression in the Train data:\", round(mini_lrS_train_MSE_score,4))\n",
    "mini_lrS_train_R2_score = r2_score(mini_y_train, mini_y_train_pred_lrS)\n",
    "print(\"R2 for the Simple Linear Regression in the Train data:\", round(mini_lrS_train_R2_score,4))\n",
    "\n",
    "MileF_test = mini_X2_test[:,0:5]\n",
    "mini_y_test_pred_lrS = mini_est_S.predict(MileF_test)\n",
    "mini_lrS_test_MSE_score = mean_squared_error(mini_y_test, mini_y_test_pred_lrS)\n",
    "print(\"MSE for the Simple Linear Regression in the Test data:\", round(mini_lrS_test_MSE_score,4))\n",
    "mini_lrS_test_R2_score = r2_score(mini_y_test, mini_y_test_pred_lrS)\n",
    "print(\"R2 for the Simple Linear Regression in the Test data:\", round(mini_lrS_test_R2_score,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Test split\n",
    "data_train, data_test = train_test_split(data, test_size=0.25, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_indexes = data.columns[0:20]\n",
    "### Standarize numerical variables in Train Set\n",
    "scaler = StandardScaler()\n",
    "data_train_scale = data_train.copy(deep=True)\n",
    "data_train_scale[col_indexes] = scaler.fit_transform(data_train[col_indexes].to_numpy()) \n",
    "display(data_train_scale.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standarize numerical variables in Test Set\n",
    "scaler = StandardScaler()\n",
    "data_test_scale = data_test.copy(deep=True)\n",
    "data_test_scale[col_indexes] = scaler.fit_transform(data_test[col_indexes].to_numpy()) \n",
    "display(data_test_scale.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train_scale.loc[:, data_train_scale.columns != 'liters_per_hour'].values\n",
    "y_train = data_train_scale['liters_per_hour'].values\n",
    "\n",
    "X_test = data_test_scale.loc[:, data_test_scale.columns != 'liters_per_hour'].values\n",
    "y_test = data_test_scale['liters_per_hour'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.Lasso(alpha=0.05)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(clf,X_train,y_train,scoring='r2',cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "def get_ridge_lasso_coeff(x,y,min_alpha_exp, max_alpha_exp, reg='Lasso',cv=True):\n",
    "    '''\n",
    "    builds multiple ridge or lasso models for 50 values of alpha between \n",
    "    10^(min_alpha_exp) to 10^(max_alpha_exp)\n",
    "    \n",
    "    Returns array of alphas and cooresponding coefficient for each feature\n",
    "    '''\n",
    "    nalphas = 50\n",
    "    nfeatures = len(x[0])\n",
    "    coefs = np.zeros((nalphas, nfeatures))\n",
    "    scores = np.zeros(nalphas)\n",
    "    alphas = np.logspace(min_alpha_exp, max_alpha_exp, nalphas)\n",
    "    for i, alpha in enumerate(alphas):\n",
    "        if reg == 'Lasso':\n",
    "            model = Lasso(alpha=alpha,normalize=True,max_iter=2000000)\n",
    "        else:\n",
    "            model = Ridge(alpha=alpha,normalize=True,max_iter=200000)\n",
    "        model.fit(x, y)\n",
    "        if cv:\n",
    "            scores[i] = (cross_val_score(model, x, y, \n",
    "                                        scoring= 'r2',\n",
    "                                        cv=5)).mean()\n",
    "#             y_pred = model.predict(x)\n",
    "#             scores[i] = mean_squared_log_error(y, y_pred)\n",
    "#         else:\n",
    "            # Note the test data used for scoring is specific to the polynomial degree 30 data\n",
    "#             scores[i] =np.sqrt(np.sum((model.predict(x30_test) - y_ex1_test)**2)) #model.score(x30_test,y_ex1_test)\n",
    "        coefs[i] = model.coef_\n",
    "    return alphas, coefs, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_alpha_v_coef(ax, alphas, coefs, column_names, method='Lasso'):\n",
    "    '''\n",
    "    plots alpha versus the beta coefficients \n",
    "    '''\n",
    "    for feature in range(len(coefs[0])):\n",
    "        if np.absolute(coefs[0,feature]) > 0.1 or feature == 2:  # only plot large coefficients + 3 order\n",
    "            ax.plot(alphas, coefs[:, feature],\n",
    "                     label=\"$\\\\beta_{{{}}}$\".format(column_names[feature]))  #'{} order'.format(feature+1))\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_title(\"$\\\\beta$ as a function of $\\\\alpha$ for {} regression\".format(method))\n",
    "    ax.set_xlabel(\"$\\\\alpha$\")\n",
    "    ax.set_ylabel(\"$\\\\beta$\")\n",
    "    ax.legend(loc=\"upper left\",bbox_to_anchor=(1,1))\n",
    "\n",
    "def plot_alpha_v_scores(ax, alphas, scores):\n",
    "    '''\n",
    "    plots alpha versus the RMSE\n",
    "    '''\n",
    "    ax.plot(alphas,scores,c='k')\n",
    "    ax.scatter(alphas[np.argmax(scores)],scores.max(), c='k', s=100)\n",
    "    print('The best R2 is {}'.format( scores.max() ))\n",
    "    ax.set_title('Model score as a function of $\\\\alpha$')\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlabel(\"$\\\\alpha$\")\n",
    "    ax.set_ylabel('$R^{2}$');    #'$R^{2}$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names =  data_train.columns[data_train.columns != 'liters_per_hour']\n",
    "\n",
    "alphas, coefs, scores = get_ridge_lasso_coeff(X_train,y_train,-5.5,-2.5, reg='Lasso',cv=True)\n",
    "fig, ax = plt.subplots(2,1,figsize=(10,8))\n",
    "plot_alpha_v_coef(ax[0], alphas, coefs, column_names, method='Lasso')\n",
    "plot_alpha_v_scores(ax[1], alphas, scores)\n",
    "fig.tight_layout()\n",
    "fig.savefig(f'figures/Lasso_coefficients_mileage.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names =  data_train.columns[data_train.columns != 'liters_per_hour']\n",
    "\n",
    "alphas, coefs, scores = get_ridge_lasso_coeff(X_train,y_train,-2,1, reg='Ridge',cv=True)\n",
    "fig, ax = plt.subplots(2,1,figsize=(10,8))\n",
    "plot_alpha_v_coef(ax[0], alphas, coefs, column_names, method='Ridge')\n",
    "plot_alpha_v_scores(ax[1], alphas, scores)\n",
    "fig.tight_layout()\n",
    "fig.savefig(f'figures/Ridge_coefficients_mileage.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.columns[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Rename speciic columns\n",
    "data_train.rename(columns = {'CEM - Pedal del acelerador arriba del 50% con vehículo detenido':'CEM - Pedal del acelerador arriba del 50p on vehículo detenido'}, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}